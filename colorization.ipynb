{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The architecture of the model used is as followed :\n",
    "    - The model follows an encoder - decoder architecture where encode extracts the low-level features from the input grayscale image and the decoder predicts the ab channels in the LAB color space\n",
    "    - The fusion layer concatenates both the low-level features which captures the texture information and the high-level features which captures the semantic information which helps the decoder in better prediction of ab channels.\n",
    "    - The encoder layer consists of 7 convolution layers which helps in downsampling the image and extract the low-level features.\n",
    "    - The decoder layer consists of 3 convulotion layers (conv8_1, conv8_2, conv8_3) which helps in upsampling the low-level feature maps to predict the ab channels.\n",
    "    - The output of the decoder layer is added to L layer of the input image to obtain the colorized image.\n",
    "\n",
    "- During testing, the pre-trained model takes a input grayscale image and passes it through the encoder and decoder layer and predicts the ab color channels which are then added to the L channel of the input image to obtain the final colorized image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "convNet_architecture_path = 'models/colorization_deploy_v2.prototxt'    # This file contains the entire architecture for the underlying convolutional neural network \n",
    "preTrained_weights_path = 'models/colorization_release_v2.caffemodel'   # This file contains the weights from the pre-trained model which we make use for the prediction of the a,b channels for the new image\n",
    "clusterCenters_path = 'models/hull_pts.npy'    # This file contains the cluster points which are obtained after the quantization of the a,b color space and these cluster points are such that they cover the entire color space \n",
    "\n",
    "img_path = 'nature.jpg'\n",
    "\n",
    "model = cv2.dnn.readNetFromCaffe(convNet_architecture_path, preTrained_weights_path)\n",
    "points = np.load(clusterCenters_path)\n",
    "\n",
    "points = points.transpose().reshape(2, 313, 1, 1)\n",
    "model.getLayer(model.getLayerId('class8_ab')).blobs = [points.astype(np.float32)]   # This is the layer that is responsible for the prediction of the ab channels\n",
    "model.getLayer(model.getLayerId('conv8_313_rh')).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")] # This is the layer that provides the 313 bins which are obtained after quantization of a continous color space to a discrete color space and this is the input to the 'class8_ab' layer\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "bw_img = img.astype(\"float32\") / 255.0\n",
    "lab_img = cv2.cvtColor(bw_img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "resized_img = cv2.resize(lab_img, (224, 224))\n",
    "L = cv2.split(resized_img)[0]       # L channel is extracted from the normalized input image\n",
    "L -= 60\n",
    "\n",
    "model.setInput(cv2.dnn.blobFromImage(L))    # The obtained L channel is sent as the input to the model to make the prediction\n",
    "ab_channel = model.forward()[0, :, :, :].transpose((1, 2, 0))\n",
    "\n",
    "ab_channel = cv2.resize(ab_channel, (img.shape[1], img.shape[0]))\n",
    "L = cv2.split(lab_img)[0]\n",
    "\n",
    "colorized = np.concatenate((L[:, :, np.newaxis], ab_channel), axis=2)   # The obtained ab channel predidction is concatenated with the L channel to obtain the final image in LAB color space\n",
    "colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)  # The image in the LAB color space is then converted into RGB color space and displayed\n",
    "colorized = (255.0 * colorized).astype(\"uint8\")\n",
    "\n",
    "cv2.imshow(\"Input Image\", bw_img)\n",
    "cv2.imshow(\"Output Image\", colorized)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
